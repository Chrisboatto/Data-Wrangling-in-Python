{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Wrangling\n",
    "\n",
    "#What is the purpose of Data Wrangling?\n",
    "\n",
    "#Data Wrangling is the process of converting data from the initial format to a format that may be better for analysis.\n",
    "\n",
    "#What is the fuel consumption (L/100k) rate for the diesel car?\n",
    "\n",
    "\n",
    "#Import Data\n",
    "\n",
    "#Import pandas\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data set from the URL and adding the related headers.\n",
    "\n",
    "filename = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/auto.csv\"\n",
    "\n",
    "#Python list headers containing name of headers\n",
    "\n",
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the Pandas method <b>read_csv() to load the data from the web address.\n",
    "#Set the parameter  \"names\" equal to the Python list \"headers\".\n",
    "\n",
    "df = pd.read_csv(filename, names = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the method head() to display the first five rows of the dataframe. \n",
    "    \n",
    "#To see what the data set looks like, we'll use the head() method.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see, several question marks appeared in the dataframe; those are missing values which may hinder our further analysis. \n",
    "\n",
    "#So, how do we identify all those missing values and deal with them?\n",
    "\n",
    "#How to work with missing data?\n",
    "\n",
    "#Steps for working with missing data:\n",
    "\n",
    "    #dentify missing data\n",
    "    #deal with missing data\n",
    "    #<li>correct data format\n",
    "    \n",
    "    \n",
    "#Identify and handle missing values\n",
    "\n",
    "#Identify missing values\n",
    "\n",
    "#Convert \"?\" to NaN\n",
    "\n",
    "#In the car dataset, missing data comes with the question mark \"?\".\n",
    "#We replace \"?\" with NaN (Not a Number), which is Python's default missing value marker, for reasons of computational speed and convenience. Here we use the function: \n",
    " #.replace(A, B, inplace = True)\n",
    "#to replace A by B\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# replace \"?\" to NaN\n",
    "df.replace(\"?\", np.nan, inplace = True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify_missing_values\n",
    "\n",
    "#Evaluating for Missing Data\n",
    "\n",
    "#The missing values are converted to Python's default. We use Python's built-in functions to identify these missing values. There are two methods to detect missing data:\n",
    "\n",
    "    #.isnull()\n",
    "    #.notnull()\n",
    "\n",
    "#The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n",
    "\n",
    "missing_data = df.isnull()\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"True\" stands for missing value, while \"False\" stands for not missing value.\n",
    "\n",
    "#Count missing values in each column\n",
    "\n",
    "#Using a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value, \"False\"  means the value is present in the dataset.  In the body of the for loop the method  \".value_counts()\"  counts the number of \"True\" values. \n",
    "\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the summary above, each column has 205 rows of data, seven columns containing missing data:\n",
    "\n",
    "    #\"normalized-losses\": 41 missing data\n",
    "    #\"num-of-doors\": 2 missing data\n",
    "    #\"bore\": 4 missing data\n",
    "    #\"stroke\" : 4 missing data\n",
    "    #\"horsepower\": 2 missing data\n",
    "    #\"peak-rpm\": 2 missing data\n",
    "    #\"price\": 4 missing data\n",
    "\n",
    "#Deal with missing data\n",
    "#How to deal with missing data?\n",
    "\n",
    "    #drop data\n",
    "        #a. drop the whole row\n",
    "        #b. drop the whole column\n",
    "    \n",
    "    #replace data\n",
    "        #a. replace it by mean\n",
    "        #b. replace it by frequency\n",
    "        #c. replace it based on other function\n",
    "        \n",
    "#Whole columns should be dropped only if most entries in the column are empty. \n",
    "#In our dataset, none of the columns are empty enough to drop entirely.\n",
    "#We have some freedom in choosing which method to replace data; however, some methods may seem more reasonable than others. \n",
    "#We will apply each method to many different columns:\n",
    "\n",
    "#Replace by mean:\n",
    "\n",
    "    #\"normalized-losses\": 41 missing data, replace them with mean\n",
    "    #\"stroke\": 4 missing data, replace them with mean\n",
    "    #\"bore\": 4 missing data, replace them with mean\n",
    "    #\"horsepower\": 2 missing data, replace them with mean\n",
    "    #\"peak-rpm\": 2 missing data, replace them with mean\n",
    "\n",
    "#Replace by frequency:\n",
    "\n",
    "    #\"num-of-doors\": 2 missing data, replace them with \"four\". \n",
    "        \n",
    "        #Reason: 84% sedans is four doors. Since four doors is most frequent, it is most likely to occur\n",
    "\n",
    "#Drop the whole row:\n",
    "\n",
    "    #\"price\": 4 missing data, simply delete the whole row\n",
    "        \n",
    "        #Reason: price is what we want to predict. Any data entry without price data cannot be used for prediction; therefore any row now without price data is not useful to us\n",
    "\n",
    "        \n",
    "#Calculate the average of the column \n",
    "\n",
    "avg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\n",
    "print(\"Average of normalized-losses:\", avg_norm_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace \"NaN\" by mean value in \"normalized-losses\" column\n",
    "\n",
    "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean value for 'bore' column\n",
    "\n",
    "avg_bore=df['bore'].astype('float').mean(axis=0)\n",
    "print(\"Average of bore:\", avg_bore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NaN by mean value\n",
    "\n",
    "df[\"bore\"].replace(np.nan, avg_bore, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question  #1:\n",
    "\n",
    "#According to the example above, replace NaN in \"stroke\" column by mean.\n",
    "\n",
    "# Write your code below and press Shift+Enter to execute \n",
    "avg_stroke = df['stroke'].astype('float').mean(axis = 0)\n",
    "\n",
    "df['stroke'].replace(np.nan, avg_stroke, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean value for the  'horsepower' column:\n",
    "\n",
    "avg_horsepower = df['horsepower'].astype('float').mean(axis=0)\n",
    "print(\"Average horsepower:\", avg_horsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NaN by mean value:\n",
    "\n",
    "df['peak-rpm'].replace(np.nan, avg_peakrpm, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see which values are present in a particular column, we can use the \".value_counts()\" method:\n",
    "\n",
    "df['num-of-doors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that four doors are the most common type. We can also use the \".idxmax()\" method to calculate for us the most common type automatically:\n",
    "\n",
    "df['num-of-doors'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The replacement procedure is very similar to what we have seen previously\n",
    "\n",
    "#replace the missing 'num-of-doors' values by the most frequent \n",
    "df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, let's drop all rows that do not have price data:\n",
    "\n",
    "# simply drop whole row with NaN in \"price\" column\n",
    "df.dropna(subset=[\"price\"], axis=0, inplace=True)\n",
    "\n",
    "# reset index, because we droped two rows\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct data format\n",
    "#We are almost there!\n",
    "#The last step in data cleaning is checking and making sure that all data is in the correct format (int, float, text or other).\n",
    "\n",
    "#In Pandas, we use \n",
    "#.dtype() to check the data type\n",
    "#.astype() to change the data type\n",
    "\n",
    "#<h4>Lets list the data types for each column</h4>\n",
    "\n",
    "df.dftypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see above, some columns are not of the correct data type. \n",
    "#Numerical variables should have type 'float' or 'int', and variables with strings such as categories should have type 'object'.\n",
    "#For example, 'bore' and 'stroke' variables are numerical values that describe the engines, so we should expect them to be of the type 'float' or 'int';\n",
    "#however, they are shown as type 'object'.\n",
    "#We have to convert data types into a proper format for each column using the \"astype()\" method.\n",
    "\n",
    "#Convert data types to proper format\n",
    "\n",
    "df[[\"bore\", \"stroke\"]] = df[[\"bore\", \"stroke\"]].astype(\"float\")\n",
    "df[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\n",
    "df[[\"price\"]] = df[[\"price\"]].astype(\"float\")\n",
    "df[[\"peak-rpm\"]] = df[[\"peak-rpm\"]].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us list the columns after the conversion\n",
    "\n",
    "df.dftypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wonderful!\n",
    "\n",
    "#Now, we finally obtain the cleaned dataset with no missing values and all data in its proper format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-959f0dee2900>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-959f0dee2900>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    <p>We will need to apply <b>data transformation</b> to transform mpg into L/100km?</p>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Data Standardization\n",
    "\n",
    "#Data is usually collected from different agencies with different formats.\n",
    "#(Data Standardization is also a term for a particular type of data normalization, \n",
    "#where we subtract the mean and divide by the standard deviation)\n",
    "\n",
    "#What is Standardization?\n",
    "#Standardization is the process of transforming data into a common format which allows the researcher to make the meaningful comparison.\n",
    "\n",
    "#Example\n",
    "#Transform mpg to L/100km:\n",
    "#In our dataset, the fuel consumption columns \"city-mpg\" and \"highway-mpg\" are represented by mpg (miles per gallon) unit. \n",
    "#Assume we are developing an application in a country that accept the fuel consumption with L/100km standard\n",
    "#We will need to apply data transformation to transform mpg into L/100km?\n",
    "\n",
    "#The formula for unit conversion is\n",
    "#L/100km = 235 / mpg\n",
    "#We can do many mathematical operations directly in Pandas.\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mpg to L/100km by mathematical operation (235 divided by mpg)\n",
    "df['city-L/100km'] = 235/df[\"city-mpg\"]\n",
    "\n",
    "# check your transformed data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question  #2:\n",
    "\n",
    "#According to the example above, transform mpg to L/100km in the column of \"highway-mpg\", and change the name of column to \"highway-L/100km\".\n",
    "\n",
    "# Write your code below and press Shift+Enter to execute \n",
    "df['highway-L/100km'] = 235/df['highway-mpg']\n",
    "df.rename(columns = {'\"highway-mpg\"': 'highway-L/100km'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Normalization\n",
    "\n",
    "#Why normalization?\n",
    "#Normalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, \n",
    "#scaling the variable so the variance is 1, or scaling variable so the variable values range from 0 to 1\n",
    "\n",
    "#Example\n",
    "#To demonstrate normalization, let's say we want to scale the columns \"length\", \"width\" and \"height\" \n",
    "#Target: would like to Normalize those variables so their value ranges from 0 to 1.\n",
    "#Approach: replace original value by (original value)/(maximum value)\n",
    "\n",
    "# replace (original value) by (original value)/(maximum value)\n",
    "df['length'] = df['length']/df['length'].max()\n",
    "df['width'] = df['width']/df['width'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Questiont #3: \n",
    "\n",
    "#According to the example above, normalize the column \"height\".\n",
    "\n",
    "# Write your code below and press Shift+Enter to execute \n",
    "df['height'] = df['height']/df['height'].max()\n",
    "df[['length', 'width', 'height']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we can see, we've normalized \"length\", \"width\" and \"height\" in the range of [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binning\n",
    "\n",
    "#Why binning?\n",
    "\n",
    "    #Binning is a process of transforming continuous numerical variables into discrete categorical 'bins', for grouped analysis.\n",
    "\n",
    "#Example: \n",
    "#In our dataset, \"horsepower\" is a real valued variable ranging from 48 to 288, it has 57 unique values. What if we only care about the price difference between cars with high horsepower, \n",
    "#medium horsepower, and little horsepower (3 types)? Can we rearrange them into three â€˜bins' to simplify analysis? \n",
    "\n",
    "#We will use the Pandas method 'cut' to segment the 'horsepower' column into 3 bins \n",
    "\n",
    "\n",
    "#Example of Binning Data In Pandas\n",
    "\n",
    "# Convert data to correct format \n",
    "\n",
    "df[\"horsepower\"]=df[\"horsepower\"].astype(int, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets plot the histogram of horspower, to see what the distribution of horsepower looks like.\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "plt.pyplot.hist(df[\"horsepower\"])\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We would like 3 bins of equal size bandwidth so we use numpy's <code>linspace(start_value, end_value, numbers_generated</code> function.\n",
    "#Since we want to include the minimum value of horsepower we want to set start_value=min(df[\"horsepower\"]).\n",
    "#Since we want to include the maximum value of horsepower we want to set end_value=max(df[\"horsepower\"]).\n",
    "#Since we are building 3 bins of equal length, there should be 4 dividers, so numbers_generated=4.\n",
    "\n",
    "#We build a bin array, with a minimum value to a maximum value, with bandwidth calculated above. \n",
    "#The bins will be values used to determine when one bin ends and another begins.\n",
    "\n",
    "bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We set group names:\n",
    "\n",
    "group_names = ['Low', 'Medium', 'High']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We apply the function \"cut\" the determine what each value of \"df['horsepower']\" belongs to.  \n",
    "\n",
    "df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )\n",
    "df[['horsepower','horsepower-binned']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see the number of vehicles in each bin.\n",
    "\n",
    "df[\"horsepower-binned\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets plot the distribution of each bin.\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "pyplot.bar(group_names, df[\"horsepower-binned\"].value_counts())\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the dataframe above carefully, you will find the last column provides the bins for \"horsepower\" with 3 categories (\"Low\",\"Medium\" and \"High\"). \n",
    "\n",
    "#We successfully narrow the intervals from 57 to 3!\n",
    "\n",
    "\n",
    "#Bins visualization\n",
    "#Normally, a histogram is used to visualize the distribution of bins we created above. \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "a = (0,1,2)\n",
    "\n",
    "# draw historgram of attribute \"horsepower\" with bins = 3\n",
    "plt.pyplot.hist(df[\"horsepower\"], bins = 3)\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The plot above shows the binning result for attribute \"horsepower\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicator variable (or dummy variable)\n",
    "\n",
    "#What is an indicator variable?\n",
    "\n",
    "    #An indicator variable (or dummy variable) is a numerical variable used to label categories. They are called 'dummies' because the numbers themselves don't have inherent meaning. \n",
    "\n",
    "#Why we use indicator variables?\n",
    "\n",
    "    #So we can use categorical variables for regression analysis in the later modules.\n",
    "\n",
    "#Example\n",
    "    #We see the column \"fuel-type\" has two unique values, \"gas\" or \"diesel\". Regression doesn't understand words, only numbers. To use this attribute in regression analysis, we convert \"fuel-type\" into indicator variables.\n",
    "\n",
    "    #We will use the panda's method 'get_dummies' to assign numerical values to different categories of fuel type. \n",
    "    \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get indicator variables and assign it to data frame \"dummy_variable_1\" \n",
    "\n",
    "dummy_variable_1 = pd.get_dummies(df[\"fuel-type\"])\n",
    "dummy_variable_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change column names for clarity \n",
    "\n",
    "dummy_variable_1.rename(columns={'fuel-type-diesel':'gas', 'fuel-type-diesel':'diesel'}, inplace=True)\n",
    "dummy_variable_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now have the value 0 to represent \"gas\" and 1 to represent \"diesel\" in the column \"fuel-type\". \n",
    "#We will now insert this column back into our original dataset. \n",
    "\n",
    "# merge data frame \"df\" and \"dummy_variable_1\" \n",
    "df = pd.concat([df, dummy_variable_1], axis=1)\n",
    "\n",
    "# drop original column \"fuel-type\" from \"df\"\n",
    "df.drop(\"fuel-type\", axis = 1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The last two columns are now the indicator variable representation of the fuel-type variable.\n",
    "#It's all 0s and 1s now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question  #4: \n",
    "\n",
    "#As above, create indicator variable to the column of \"aspiration\": \"std\" to 0, while \"turbo\" to 1.\n",
    "\n",
    "# Write your code below and press Shift+Enter to execute \n",
    "dummy_variable_2 = pd.get_dummies(df[\"aspiration\"])\n",
    "dummy_variable_2.rename(columns={'std':'aspiration-std', 'turbo': 'aspiration-turbo'}, inplace=True)\n",
    "dummy_variable_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question  #5:\n",
    "\n",
    "#Merge the new dataframe to the original dataframe then drop the column 'aspiration'\n",
    "\n",
    "# Write your code below and press Shift+Enter to execute \n",
    "df = pd.concat([df, dummy_variable_2], axis=1)\n",
    "\n",
    "df.drop(\"aspiration\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the new csv\n",
    "\n",
    "df.to_csv('clean_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
